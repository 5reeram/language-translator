{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b2c5964-b122-4b6a-a118-574e0041eb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "# Load trained model\n",
    "model = load_model('s2s.h5')\n",
    "\n",
    "# Load data for encoding and decoding\n",
    "with open('training_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "input_characters = data['input_characters']\n",
    "target_characters = data['target_characters']\n",
    "max_input_length = data['max_input_length']\n",
    "max_target_length = data['max_target_length']\n",
    "num_en_chars = data['num_en_chars']\n",
    "num_dec_chars = data['num_dec_chars']\n",
    "\n",
    "def encode_input_text(input_text):\n",
    "    input_text = input_text.lower()\n",
    "    input_text = input_text[:max_input_length]  # Truncate if necessary\n",
    "    en_in_data = np.zeros((1, max_input_length, num_en_chars), dtype='float32')\n",
    "    for t, char in enumerate(input_text):\n",
    "        if char in input_characters:\n",
    "            en_in_data[0, t, input_characters.index(char)] = 1.0\n",
    "        else:\n",
    "            print(f\"Character '{char}' not in input_characters, ignoring.\")\n",
    "    return en_in_data\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    target_seq = np.zeros((1, 1, num_dec_chars))\n",
    "    target_seq[0, 0, target_characters.index('\\t')] = 1.0\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        \n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = target_characters[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "        \n",
    "        if sampled_char == '\\n' or len(decoded_sentence) > max_target_length:\n",
    "            stop_condition = True\n",
    "        \n",
    "        target_seq = np.zeros((1, 1, num_dec_chars))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.0\n",
    "        states_value = [h, c]\n",
    "    \n",
    "    return decoded_sentence\n",
    "\n",
    "# Load the encoder and decoder models separately\n",
    "encoder_inputs = model.input[0]\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_inputs = model.input[1]\n",
    "decoder_state_input_h = Input(shape=(256,), name='input_3')\n",
    "decoder_state_input_c = Input(shape=(256,), name='input_4')\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_lstm = model.layers[3]\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "decoder_dense = model.layers[4]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "def translate_text():\n",
    "    input_text = input_entry.get()\n",
    "    if not input_text:\n",
    "        messagebox.showwarning(\"Input Error\", \"Please enter some text to translate.\")\n",
    "        return\n",
    "    \n",
    "    input_seq = encode_input_text(input_text)\n",
    "    translated_text = decode_sequence(input_seq)\n",
    "    \n",
    "    output_label.config(text=f\"Translated Text: {translated_text}\")\n",
    "\n",
    "# Create the main window\n",
    "root = tk.Tk()\n",
    "root.title(\"English to French Translator\")\n",
    "\n",
    "# Create and place widgets\n",
    "input_label = tk.Label(root, text=\"Enter English Text:\")\n",
    "input_label.pack(pady=5)\n",
    "\n",
    "input_entry = tk.Entry(root, width=50)\n",
    "input_entry.pack(pady=5)\n",
    "\n",
    "translate_button = tk.Button(root, text=\"Translate\", command=translate_text)\n",
    "translate_button.pack(pady=5)\n",
    "\n",
    "output_label = tk.Label(root, text=\"Translated Text:\")\n",
    "output_label.pack(pady=5)\n",
    "\n",
    "# Run the GUI event loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c748e528-de02-4842-bb8b-7e4c1ff62d62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
